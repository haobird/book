# Redis

## Redis代理

### Codis


## 分布式部署

### 主从 

读写分离，备份，一个Master可以有多个Slaves。

主从模式：备份数据、负载均衡，一个Master可以有多个Slaves。

通过执行slaveof命令或设置slaveof选项，让一个服务器去复制另一个服务器的数据。被复制的服务器称为：Master主服务；对主服务器进行复制的服务器称为：Slave从服务器。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。

主从复制问题：当master down，需要手动将一台slave使用slaveof no one提升为master要实现自动，就需要redis哨兵。

注意：5.0的版本叫做replicaof   ， 5.0之前的叫 slaveof

实现原理步骤：

1. 从服务器向主服务器发送SYNC命令
2. 主服务器收到SYNC命令后，执行BGSAVE命令，在后台生成RDB文件，使用缓冲区记录从现在开始执行的所有的写命令。
3. 当主服务器的BGSAVE命令执行完毕后，主服务器后将BGSAVE命令生成的RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器执行BGSAVE命令时的数据库状态。
4. 主服务器将记录在缓冲区里面的所有写命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务器数据库当前所处的状态。

![主从复制](https://pic4.zhimg.com/v2-3b1a7afce7d8db295bab64cebadeac43_b.jpg)


### 哨兵（Sentinel）

监控，自动转移，哨兵发现主服务器挂了后，就会从slave中重新选举一个主服务器。

sentinel发现master挂了后，就会从slave中重新选举一个master。

为了解决Redis的主从复制的不支持高可用性能，Redis实现了Sentinel哨兵机制解决方案。由一个或多个Sentinel去监听任意多个主服务以及主服务器下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线的主服务器属下的某个从服务器升级为新的主服务器，然后由新的主服务器代替已经下线的从服务器，并且Sentinel可以互相监视。

![sentinel](https://pic4.zhimg.com/v2-f5480293b5691474d9efceb5d3abd47f_b.jpg)

![主服务器下线](https://pic4.zhimg.com/v2-ef1a596022416a42b579f2549386f54b_b.jpg)

当有多个Sentinel，在进行监视和转移主从服务器时，Sentinel之间会自己首先进行选举，选出Sentinel的leader来进行执行任务。

### 集群

#### 集群概念

为了解决单机Redis容量有限的问题，将数据按一定的规则分配到多台机器，内存/QPS不受限于单机，可受益于分布式集群高扩展性。

cluster是为了解决单机Redis容量有限的问题，将数据按一定的规则分配到多台机器。


sentinel着眼于高可用，Cluster提高并发量。

集群是Redis提供的分布式数据库方案，集群通过分片来进行数据共享，并提供复制和故障转移功能。一个Redis集群通常由多个节点组成；最初，每个节点都是独立的，需要将独立的节点连接起来才能形成可工作的集群。
Redis集群是一个由多个节点组成的分布式服务器群，它具有复制、高可用和分片特性；Redis集群没有中心节点，并且带有复制和故障转移特性，这可以避免单个节点成为性能瓶颈，或者因为某个节点下线而导致整个集群下线；

Cluster Nodes命令和Cluster Meet命令，添加和连接节点形成集群。

![集群1](https://pic2.zhimg.com/v2-c93e8cc3b0bd2228f6096b7aa309bcbd_b.jpg)

Redis中的集群分为主节点和从节点。其中主节点用于处理槽；而从节点用于复制某个主节点，并在被复制的主节点下线时，代替下线的主节点继续处理命令请求。

![集群2](https://pic3.zhimg.com/v2-44ac5e9f378e641b2f8c86542d54f46a_b.jpg)

![集群3](https://pic3.zhimg.com/v2-3deaac4968c53a6555f214cdb6c183b6_b.jpg)


#### 集群的几种方案

1. Replication+Sentinel

这里Sentinel的作用有三个: - 监控:Sentinel 会不断的检查主服务器和从服务器是否正常运行。 - 通知:当被监控的某个redis服务器出现问题，Sentinel通过API脚本向管理员或者其他的应用程序发送通知。 - 自动故障转移:当主节点不能正常工作时，Sentinel会开始一次自动的故障转移操作，它会将与失效主节点是主从关系 的其中一个从节点升级为新的主节点，并且将其他的从节点指向新的主节点。

工作原理就是，当Master宕机的时候，Sentinel会选举出新的Master，并根据Sentinel中client-reconfig-script脚本配置的内容，去动态修改VIP(虚拟IP)，将VIP(虚拟IP)指向新的Master。我们的客户端就连向指定的VIP即可！ 故障发生后的转移情况，可以理解为下图

![图片](https://pic2.zhimg.com/v2-34c8a45a7ed76cf5283835014e712c3d_b.jpg)

缺陷: (1)主从切换的过程中会丢数据 (2)Redis只能单点写，不能水平扩容

2. Proxy+Replication+Sentinel （codis）

这里的Proxy目前有两种选择:Codis和Twemproxy。我经历这套架构的时间为2015年，当时我好像咨询过我的主管为啥不用Codis和Redis官网的Redis Cluster。原因有二: - 据说是因为Codis开源的比较晚，考虑到更换组件的成本问题。毕竟本来运行好好的东西，你再去换组件，风险是很大的。 - Redis Cluster在2015年还是试用版，不保证会遇到什么问题，因此不敢尝试。

所以我没接触过Codis，之前一直用的是Twemproxy作为Proxy。 这里以Twemproxy为例说明，如下图所示

![图片](https://pic3.zhimg.com/v2-6d7bad5eb0194712cb0338252c205c46_b.jpg)

工作原理如下 - 前端使用Twemproxy+KeepAlived做代理，将其后端的多台Redis实例分片进行统一管理与分配 - 每一个分片节点的Slave都是Master的副本且只读 - Sentinel持续不断的监控每个分片节点的Master，当Master出现故障且不可用状态时，Sentinel会通知/启动自动故障转移等动作 - Sentinel 可以在发生故障转移动作后触发相应脚本（通过 client-reconfig-script 参数配置 ），脚本获取到最新的Master来修改Twemproxy配置

缺陷: (1)部署结构超级复杂 (2)可扩展性差，进行扩缩容需要手动干预 (3)运维不方便


3. Redis Cluster

我经历这套架构的时间为2017年，在这个时间Redis Cluster已经很成熟了！你们在网上能查到的大部分缺点，在我接触到的时候基本已经解决! 比如没有完善的运维工具？可以参照一下搜狐出的CacheCloud。 比如没有公司在生产用过？我接触到的时候，百度贴吧，美团等大厂都用过了。 比如没有Release版？我接触到的时候距离Redis Cluster发布Release版已经很久。 而且毕竟是官网出的，肯定会一直维护、更新下去，未来必定会更加成熟、稳定。换句话说，Redis不倒，Redis Cluster就不会放弃维护。所以，我推荐还是这套架构! 如下图所示

![图片](https://pic3.zhimg.com/v2-db753d3dc49c6118363eabeac7d69c9a_b.jpg)

工作原理如下 - 客户端与Redis节点直连,不需要中间Proxy层，直接连接任意一个Master节点 - 根据公式HASH_SLOT=CRC16(key) mod 16384，计算出映射到哪个分片上，然后Redis会去相应的节点进行操作

具有如下优点: (1)无需Sentinel哨兵监控，如果Master挂了，Redis Cluster内部自动将Slave切换Master (2)可以进行水平扩容 (3)支持自动化迁移，当出现某个Slave宕机了，那么就只有Master了，这时候的高可用性就无法很好的保证了，万一master也宕机了，咋办呢？ 针对这种情况，如果说其他Master有多余的Slave ，集群自动把多余的Slave迁移到没有Slave的Master 中。

缺点: (1)批量操作是个坑 (2)资源隔离性较差，容易出现相互影响的情况。

#### Redis Cluster的增减步骤

```
# 新建一个 7006 节点，让其作为一个新的主节点加入：
# add-node是加入指令，127.0.0.1:7006 表示新加入的节点，127.0.0.1:7000 表示加入的集群的一个节点，用来辨识是哪个集群，理论上哪个都可以。
redis-trib.rb add-node 127.0.0.1:7006 127.0.0.1:7000

# 查看集群节点状态
redis-trib.rb check 127.0.0.1:7000

# 客户端查看集群中节点状态
redis-cli -c -p 7006
127.0.0.1:7006> cluster nodes

# redis cluster 不是在新加节点的时候帮我们做好了迁移工作，需要我们手动对集群进行重新分片迁移，也是这个命令：
redis-trib.rb reshard 127.0.0.1:7000

# 提示我们需要迁移多少slot到7006上，我们可以算一下：16384/4 = 4096，也就是说，为了平衡分配起见，我们需要移动4096个槽点到7006上。
# 此时又提示我们，接受的node ID是多少，7006的id 我们通过上面就可以看到是fe595e7a38c659a6eb6949bb31fd7474881d6422
# 如果我们不打算从特定的节点上取出指定数量的哈希槽， 那么可以向 redis-trib 输入 all
# 迁移完毕之后，我们来检查下：
redis-trib.rb check 127.0.0.1:7000

# 让节点作为从节点加入集群
redis-trib.rb add-node --slave 127.0.0.1:7007 127.0.0.1:7000
# 上面的过程是集群自动分配主节点给新加入的从节点。 
redis-trib.rb add-node --slave --master-id fe595e7a38c659a6eb6949bb31fd7474881d6422 127.0.0.1:7008 127.0.0.1:7003
# –master-id 表示指定的主节点node id。这里指定的是 7006 这个主节点。

# 移除集群中某个节点 
# redis-trib del-node 127.0.0.1:7000 `<node-id>`
redis-trib.rb del-node 127.0.0.1:7000 fe595e7a38c659a6eb6949bb31fd7474881d6422

# 由于7006里面已经有数据了，不能被移除，要先将它的数据转移出去。也就是说得重新分片，用上面增加新节点后的分片方式一样，用我们再来一遍：
redis-trib.rb reshard 127.0.0.1:7000
# 提示，我们要分多少个槽点，由于7007上有4096个槽点，所以这里填写4096
# 提示我们，需要移动到哪个id上，那就填7001的吧：

# 移除一个从节点
# 移除一个从节点就简单的多了，因为不需要考虑数据的迁移，我们7008给移除：
redis-trib.rb del-node 127.0.0.1:7003 357c88af6960a11c130e0180038f8d095179b8e7

```


## Redis 其它问题

### 持久化实现

#### 1、RDB快照（全量备份）

RDB快照是某个时间点的一次全量数据备份，是二进制文件，在存储上非常紧凑。

1.1 触发机制

RDB持久化触发机制分为：手动触发和自动触发 手动触发

save命令：会阻塞当前服务器，直到RDB完成为止，如果数据量大的话会造成长时间的阻塞，线上环境一般禁止使用 bgsave命令：就是background save，执行bgsave命令时Redis主进程会fork一个子进程来完成RDB的过程，完成后自动结束（操作系统的多进程Copy On Write机制，简称COW）。所以Redis主进程阻塞时间只有fork阶段的那一下。相对于save，阻塞时间很短。

自动触发

场景一：配置redis.conf，触发规则，自动执行

```
# 当在规定的时间内，Redis发生了写操作的个数满足条件，会触发发生BGSAVE命令。
# save <seconds> <changes>
# 当用户设置了多个save的选项配置，只要其中任一条满足，Redis都会触发一次BGSAVE操作
save 900 1 
save 300 10 
save 60 10000
# 以上配置的含义：900秒之内至少一次写操作、300秒之内至少发生10次写操作、
# 60秒之内发生至少10000次写操作，只要满足任一条件，均会触发bgsave
```

场景二：执行shutdown命令关闭服务器时，如果没有开启AOF持久化功能，那么会自动执行一次bgsave

场景三：主从同步（slave和master建立同步机制）

![主从同步](https://pic3.zhimg.com/v2-2fec2f1675ac45234f63d94bdab2bfd6_b.jpg)

1.2 RDB执行流程

Redis 使用操作系统的多进程 cow(Copy On Write) 机制来实现RDB快照持久化

1. 执行bgsave命令的时候，Redis主进程会检查是否有子进程在执行RDB/AOF持久化任务，如果有的话，直接返回
2. Redis主进程会fork一个子进程来执行执行RDB操作，fork操作会对主进程造成阻塞（影响Redis的读写），fork操作完成后会发消息给主进程，从而不再阻塞主进程。（阻塞仅指主进程fork子进程的过程，后续子进程执行操作时不会阻塞）
3. RDB子进程会根据Redis主进程的内存生成临时的快照文件，持久化完成后会使用临时快照文件替换掉原来的RDB文件。（该过程中主进程的读写不受影响，但Redis的写操作不会同步到主进程的主内存中，而是会写到一个临时的内存区域作为一个副本）
4. 子进程完成RDB持久化后会发消息给主进程，通知RDB持久化完成（将上阶段内存副本中的增量写数据同步到主内存）

1.3 RDB的优缺点

优点

- RDB文件小，非常适合定时备份，用于灾难恢复
- Redis加载RDB文件的速度比AOF快很多，因为RDB文件中直接存储的时内存数据，而AOF文件中存储的是一条条命令，需要重演命令。

缺点

- RDB无法做到实时持久化，若在两次bgsave间宕机，则会丢失区间（分钟级）的增量数据，不适用于实时性要求较高的场景
- RDB的cow机制中，fork子进程属于重量级操作，并且会阻塞redis主进程
- 存在老版本的Redis不兼容新版本RDB格式文件的问题

#### 2、AOF日志（连续的增量备份）

AOF日志是持续增量的备份，是基于写命令存储的可读的文本文件。AOF日志会在持续运行中持续增大，由于Redis重启过程需要优先加载AOF日志进行指令重放以恢复数据，恢复时间会无比漫长。所以需要定期进行AOF重写，对AOF日志进行瘦身。目前AOF是Redis持久化的主流方式。

2.1 开启方式

AOF默认是关闭的，通过redis.conf配置文件进行开启

```
## 此选项为aof功能的开关，默认为“no”，可以通过“yes”来开启aof功能  
## 只有在“yes”下，aof重写/文件同步等特性才会生效  
appendonly yes  

## 指定aof文件名称  
appendfilename appendonly.aof  

## 指定aof操作中文件同步策略，有三个合法值：always everysec no,默认为everysec  
appendfsync everysec  
## 在aof-rewrite期间，appendfsync是否暂缓文件同步，"no"表示“不暂缓”，“yes”表示“暂缓”，默认为“no”  
no-appendfsync-on-rewrite no  

## aof文件rewrite触发的最小文件尺寸(mb,gb),只有大于此aof文件大于此尺寸是才会触发rewrite，默认“64mb”，建议“512mb”  
auto-aof-rewrite-min-size 64mb  

## 相对于“上一次”rewrite，本次rewrite触发时aof文件应该增长的百分比  
## 每一次rewrite之后，redis都会记录下此时“新aof”文件的大小(例如A)
## aof文件增长到A*(1 + p)之后，触发下一次rewrite，每一次aof记录的添加，都会检测当前aof文件的尺寸。  
auto-aof-rewrite-percentage 100
```

AOF是文件操作，对于变更操作比较密集的server，那么将造成磁盘IO的负荷加重。此外linux对文件操作采取了“延迟写入”手段，即并非每次write操作都会触发实际磁盘操作，而是进入了buffer中，当buffer数据达到阀值时触发实际写入(也有其他时机)，这是linux对文件系统的优化。

Linux 的glibc提供了fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷到磁盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 日志不丢失。但是 fsync 是一个磁盘 IO 操作，它很慢！如果 Redis 执行一条指令就要 fsync 一次，那么 Redis 高性能的地位就不保了。

因此在上述配置文件中，可观察到Redis中提供了3中AOF记录同步选项：

- always：每一条AOF记录都立即同步到文件，性能很低，但较为安全。
- everysec：每秒同步一次，性能和安全都比较中庸的方式，也是redis推荐的方式。如果遇到物理服务器故障，可能导致最多1秒的AOF记录丢失。
- no：Redis永不直接调用文件同步，而是让操作系统来决定何时同步磁盘。性能较好，但很不安全。

2.2 重写（rewrite）机制

AOF日志会在持续运行中持续增大，需要定期进行AOF重写，对AOF日志进行瘦身。

AOF Rewrite 虽然是“压缩”AOF文件的过程，但并非采用“基于原AOF文件”来重写或压缩，而是采取了类似RDB快照的方式：基于Copy On Write，全量遍历内存中数据，然后逐个序列到AOF文件中。因此AOF rewrite能够正确反应当前内存数据的状态。

AOF重写（bgrewriteaof）和RDB快照写入（bgsave）过程类似，二者都消耗磁盘IO。Redis采取了“schedule”策略：无论是“人工干预”还是系统触发，快照和重写需要逐个被执行。

重写过程中，对于新的变更操作将仍然被写入到原AOF文件中，同时这些新的变更操作也会被Redis收集起来。当内存中的数据被全部写入到新的AOF文件之后，收集的新的变更操作也将被一并追加到新的AOF文件中。然后将新AOF文件重命名为appendonly.aof，使用新AOF文件替换老文件，此后所有的操作都将被写入新的AOF文件。

2.3 触发机制
和RDB类似，AOF触发机制也分为：手动触发和自动触发

手动触发 直接调用bgrewriteaof命令

```
redis-cli -h ip -p port bgrewriteaof
```

自动触发

根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机

```
auto-aof-rewrite-min-size:表示运行AOF重写时文件最小体积，默认为64MB（我们线上是512MB）。

auto-aof-rewrite-percentage:代表当前AOF文件空间（aof_current_size）和上一次重写后AOF文件空间（aof_base_size）的值
```

自动触发时机：

```
(aof_current_size > auto-aof-rewrite-min-size ) && (aof_current_size - aof_base_size) / aof_base_size >= auto-aof-rewrite-percentage
```

其中aof_current_size和aof_base_size可以在info Persistence统计信息中查看。

2.4 AOF的优缺点
优点 AOF只是追加写日志文件，对服务器性能影响较小，速度比RDB要快，消耗的内存较少

缺点

- AOF方式生成的日志文件太大，需要不断AOF重写，进行瘦身。
- 即使经过AOF重写瘦身，由于文件是文本文件，文件体积较大（相比于RDB的二进制文件）。
- AOF重演命令式的恢复数据，速度显然比RDB要慢。

#### 3、Redis 4.0 混合持久化

- 仅使用RDB快照方式恢复数据，由于快照时间粒度较大，时回丢失大量数据。
- 仅使用AOF重放方式恢复数据，日志性能相对 rdb 来说要慢。在 Redis 实例很大的情况下，启动需要花费很长的时间。

Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。相当于：

- 大量数据使用粗粒度（时间上）的rdb快照方式，性能高，恢复时间快。
- 增量数据使用细粒度（时间上）的AOF日志方式，尽量保证数据的不丢失。

在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。

混合持久化是最佳方式吗？

不一定。

首先，混合持久化是Redis 4.0才引入的特性，现在很多 公司可能都还在使用3.x版本。使用不了这一特性。

另外，可以使用下面这种方式。Master使用AOF，Slave使用RDB快照，master需要首先确保数据完整性，它作为数据备份的第一选择；slave提供只读服务或仅作为备机，它的主要目的就是快速响应客户端read请求或灾切换。



## 场景问题

### 缓存穿透

缓存穿透：key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。


**解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 set -999 UNKNOWN。然后设置一个(短期的)过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。**

### 缓存击穿

缓存击穿：key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

*缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。*

**解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。**

### 雪崩问题

缓存雪崩：当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。

*对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。*

**缓存雪崩的事前事中事后的解决方案如下。 - 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。 - 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。 - 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。**



